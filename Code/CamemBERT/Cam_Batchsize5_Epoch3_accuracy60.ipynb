{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cam_Batchsize5_Epoch3_accuracy60.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcf4n4f15ZQB"
      },
      "source": [
        "# **Package importation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK910WqOauTw",
        "outputId": "2feb48e9-e64b-462d-cae5-41d75ca555ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNS0ecn-cLBJ",
        "outputId": "fc3ff258-2cb0-433c-e762-11a67d059588"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.95)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.17.83)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.83 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.20.83)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.83->boto3->transformers==2.8.0) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKTsS8qmHKM0"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count()\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split, \\\n",
        "                            DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertForSequenceClassification, CamembertTokenizer, \\\n",
        "                         AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Functions : preprocess() (create dataloaders from raw data) \n",
        "# load_models() (load tokenizers and models) training() (loop of one training step) evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZy1N0D5k7o"
      },
      "source": [
        "# **Data uploading and preparing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "p-aiyGlVhJbN",
        "outputId": "13d4ac7d-700a-4654-870e-949dbeb6627b"
      },
      "source": [
        "#upload the preprocessed dataset\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Agon.csv\")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Difficulty</th>\n",
              "      <th>Word</th>\n",
              "      <th>Types</th>\n",
              "      <th>WordDifficulty</th>\n",
              "      <th>AvgWordDiffic</th>\n",
              "      <th>newText</th>\n",
              "      <th>WordFrequency</th>\n",
              "      <th>AvgFreq</th>\n",
              "      <th>Cognates</th>\n",
              "      <th>ReadScore</th>\n",
              "      <th>AvgFreqStd</th>\n",
              "      <th>ReadScoreStd</th>\n",
              "      <th>cog</th>\n",
              "      <th>hasCog</th>\n",
              "      <th>NumOfCog</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>est pour quand</td>\n",
              "      <td>1</td>\n",
              "      <td>['est', 'pour', 'quand']</td>\n",
              "      <td>['AUX', 'ADP', 'SCONJ']</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>0.000</td>\n",
              "      <td>est pour quand</td>\n",
              "      <td>[15.6, 14.57, 13.15]</td>\n",
              "      <td>0.959484</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.993116</td>\n",
              "      <td>0.040516</td>\n",
              "      <td>0.006884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Je pense que est bon</td>\n",
              "      <td>1</td>\n",
              "      <td>['Je', 'pense', 'que', 'est', 'bon']</td>\n",
              "      <td>['PRON', 'VERB', 'SCONJ', 'AUX', 'ADJ']</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0.000</td>\n",
              "      <td>Je pense que est bon</td>\n",
              "      <td>[15.78, 12.24, 15.29, 15.6, 12.93]</td>\n",
              "      <td>0.953108</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.986232</td>\n",
              "      <td>0.046892</td>\n",
              "      <td>0.013768</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>est pas mal</td>\n",
              "      <td>1</td>\n",
              "      <td>['est', 'pas', 'mal']</td>\n",
              "      <td>['AUX', 'ADV', 'NOUN']</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>0.000</td>\n",
              "      <td>est pas mal</td>\n",
              "      <td>[15.6, 15.43, 12.15]</td>\n",
              "      <td>0.955352</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.993116</td>\n",
              "      <td>0.044648</td>\n",
              "      <td>0.006884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Qu est ce que vous faites</td>\n",
              "      <td>1</td>\n",
              "      <td>['Qu', 'est', 'ce', 'que', 'vous', 'faites']</td>\n",
              "      <td>['PRON', 'AUX', 'PRON', 'PRON', 'PRON', 'VERB']</td>\n",
              "      <td>[0.03, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0.007</td>\n",
              "      <td>Qu est ce que vous faites</td>\n",
              "      <td>[9.21, 15.6, 14.59, 15.29, 15.16, 11.58]</td>\n",
              "      <td>0.882586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.982773</td>\n",
              "      <td>0.117414</td>\n",
              "      <td>0.017227</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>est bien</td>\n",
              "      <td>1</td>\n",
              "      <td>['est', 'bien']</td>\n",
              "      <td>['AUX', 'ADV']</td>\n",
              "      <td>[0.0, 0.0]</td>\n",
              "      <td>0.000</td>\n",
              "      <td>est bien</td>\n",
              "      <td>[15.6, 14.03]</td>\n",
              "      <td>0.992694</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.996541</td>\n",
              "      <td>0.007306</td>\n",
              "      <td>0.003459</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                       Text  Difficulty  ...  cog hasCog NumOfCog\n",
              "0           0             est pour quand           1  ...  NaN      0        0\n",
              "1           1       Je pense que est bon           1  ...  NaN      0        0\n",
              "2           2                est pas mal           1  ...  NaN      0        0\n",
              "3           3  Qu est ce que vous faites           1  ...  NaN      0        0\n",
              "4           4                   est bien           1  ...  NaN      0        0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jCMZfCgNzw2Q",
        "outputId": "7d2e8ad4-e346-4037-e6f3-aee31b848b0e"
      },
      "source": [
        "#deleting all useless columns for the camambert model\n",
        "dataset.drop(['Unnamed: 0', 'Word', 'Types', 'WordDifficulty', 'AvgWordDiffic', 'newText', 'WordFrequency', 'AvgFreq', 'Cognates', 'ReadScore', 'AvgFreqStd', 'ReadScoreStd', 'cog', 'hasCog', 'NumOfCog'], axis=1, inplace=True)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>est pour quand</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je pense que est bon</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>est pas mal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Qu est ce que vous faites</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>est bien</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>Le problème va du garçon de café tentant inint...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Les lois de programmation mentionnées antépénu...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>La conscience malheureuse est donc le mauvais ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Comme Monsieur un informaticien fondateur de l...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Un passager peut se tenir califourchon derrièr...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Difficulty\n",
              "0                                        est pour quand           1\n",
              "1                                  Je pense que est bon           1\n",
              "2                                           est pas mal           1\n",
              "3                             Qu est ce que vous faites           1\n",
              "4                                              est bien           1\n",
              "...                                                 ...         ...\n",
              "4795  Le problème va du garçon de café tentant inint...           6\n",
              "4796  Les lois de programmation mentionnées antépénu...           6\n",
              "4797  La conscience malheureuse est donc le mauvais ...           6\n",
              "4798  Comme Monsieur un informaticien fondateur de l...           6\n",
              "4799  Un passager peut se tenir califourchon derrièr...           6\n",
              "\n",
              "[4800 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHEocy2pfjuy"
      },
      "source": [
        "#The 5 code below are aimed to delete proportionally 75% of rows for having enough colab ram to run completely the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnIjECR0lpOB"
      },
      "source": [
        "dataset = dataset.drop(range(4199,4799))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5aw1zXLlpC7"
      },
      "source": [
        "dataset = dataset.drop(range(3399,3999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS18JsXxlo4g"
      },
      "source": [
        "dataset = dataset.drop(range(2599,3199))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICeE7Ihglouj"
      },
      "source": [
        "dataset = dataset.drop(range(1799,2399))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ieA7EZxlok9"
      },
      "source": [
        "dataset = dataset.drop(range(999,1599))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov4m9cg9loYc"
      },
      "source": [
        "dataset = dataset.drop(range(199,799))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HBmdIfppbdY1",
        "outputId": "c0609b5a-016f-4e28-a534-89a4890389bb"
      },
      "source": [
        "#normalizing the difficulty for having a same comparing base difficulty level of the other iterations of the camambert model\n",
        "dataset = dataset.replace([1, 2, 3, 4, 5, 6], [0,1,2,3,4,5])\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>est pour quand</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je pense que est bon</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>est pas mal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Qu est ce que vous faites</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>est bien</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4195</th>\n",
              "      <td>Nous lisions ensemble des poètes anglais nous ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>Car la tentation minutieusement encouragée par...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>Puis quand ils eurent dépassé le bûcheron celu...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>Pour conjurer les deux mois de vacances ils ac...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Un passager peut se tenir califourchon derrièr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Difficulty\n",
              "0                                        est pour quand           0\n",
              "1                                  Je pense que est bon           0\n",
              "2                                           est pas mal           0\n",
              "3                             Qu est ce que vous faites           0\n",
              "4                                              est bien           0\n",
              "...                                                 ...         ...\n",
              "4195  Nous lisions ensemble des poètes anglais nous ...           5\n",
              "4196  Car la tentation minutieusement encouragée par...           5\n",
              "4197  Puis quand ils eurent dépassé le bûcheron celu...           5\n",
              "4198  Pour conjurer les deux mois de vacances ils ac...           5\n",
              "4799  Un passager peut se tenir califourchon derrièr...           5\n",
              "\n",
              "[1200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSlIQVsgb_H-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "59f38ff5-76cd-4a8f-dc0d-cc216bf0ad45"
      },
      "source": [
        "#rename the columns \n",
        "dataset.columns = ['review','sentiment']\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>est pour quand</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je pense que est bon</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>est pas mal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Qu est ce que vous faites</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>est bien</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4195</th>\n",
              "      <td>Nous lisions ensemble des poètes anglais nous ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>Car la tentation minutieusement encouragée par...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>Puis quand ils eurent dépassé le bûcheron celu...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>Pour conjurer les deux mois de vacances ils ac...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Un passager peut se tenir califourchon derrièr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 review  sentiment\n",
              "0                                        est pour quand          0\n",
              "1                                  Je pense que est bon          0\n",
              "2                                           est pas mal          0\n",
              "3                             Qu est ce que vous faites          0\n",
              "4                                              est bien          0\n",
              "...                                                 ...        ...\n",
              "4195  Nous lisions ensemble des poètes anglais nous ...          5\n",
              "4196  Car la tentation minutieusement encouragée par...          5\n",
              "4197  Puis quand ils eurent dépassé le bûcheron celu...          5\n",
              "4198  Pour conjurer les deux mois de vacances ils ac...          5\n",
              "4799  Un passager peut se tenir califourchon derrièr...          5\n",
              "\n",
              "[1200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QF8upTav5Z_X",
        "outputId": "9388fec7-c26d-4b89-98cf-256f79ed624b"
      },
      "source": [
        "#shuffling all the columns because we notice that our camembert model processed differently if there is no order in the dataset\n",
        "dataset = shuffle(dataset)\n",
        "dataset\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3279</th>\n",
              "      <td>Dans son livre Guide de survie pour accros aux...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2551</th>\n",
              "      <td>La motocyclette était très peu fiable ses débuts</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1766</th>\n",
              "      <td>Il rencontré un grand succès dans les écoles</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Qu est ce qu ils font</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>As tu prévu quelque chose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>Enfin la délivrance après soixante quatorze jo...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>Je la considérais comme une créature céleste</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>Ce était pas le cas il cent ans et est très bien</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2413</th>\n",
              "      <td>Une petite marque au front des cicatrices sur ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>Je suis bien arrivé Londres</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 review  sentiment\n",
              "3279  Dans son livre Guide de survie pour accros aux...          4\n",
              "2551   La motocyclette était très peu fiable ses débuts          3\n",
              "1766       Il rencontré un grand succès dans les écoles          2\n",
              "32                                Qu est ce qu ils font          0\n",
              "1652                          As tu prévu quelque chose          2\n",
              "...                                                 ...        ...\n",
              "3264  Enfin la délivrance après soixante quatorze jo...          4\n",
              "2547       Je la considérais comme une créature céleste          3\n",
              "818    Ce était pas le cas il cent ans et est très bien          1\n",
              "2413  Une petite marque au front des cicatrices sur ...          3\n",
              "946                         Je suis bien arrivé Londres          1\n",
              "\n",
              "[1200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBFyHkD65NDR"
      },
      "source": [
        "## **Camembert Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shklKqs4cCyT"
      },
      "source": [
        "reviews = dataset['review'].values.tolist()\n",
        "sentiments = dataset['sentiment'].values.tolist()\n",
        "\n",
        "TOKENIZER = CamembertTokenizer.from_pretrained(\n",
        "    'camembert-base',\n",
        "    do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfs9Ot9N4jdz"
      },
      "source": [
        "def preprocess(raw_reviews, sentiments=None):\n",
        "    \"\"\"\n",
        "    Cette fonction prends de la donnée brute en argument et retourne un 'dataloader' pytorch\n",
        "\n",
        "    Args\n",
        "        raw_reviews (array-like) : Une liste de reviews sous forme de 'str'\n",
        "        \n",
        "        sentiments : Une liste 'sentiments' (0 = negatif, 1 = positif) de la meme taille que\n",
        "                     'raw_review'\n",
        "    \n",
        "    Returns\n",
        "        inputs_ids, attention_masks, sentiments(optionel) : Objet  de PyTorch qui contient \n",
        "                    les versions tokenisees et encodees des donnees brutes\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    encoded_batch = TOKENIZER.batch_encode_plus(raw_reviews,\n",
        "                                                add_special_tokens=False,\n",
        "                                                pad_to_max_length=True,\n",
        "                                                return_attention_mask=True,\n",
        "                                                return_tensors = 'pt')\n",
        "    if sentiments:\n",
        "        sentiments = torch.tensor(sentiments)\n",
        "        return encoded_batch['input_ids'], encoded_batch['attention_mask'], sentiments\n",
        "    return encoded_batch['input_ids'], encoded_batch['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-6WezGJpJu-"
      },
      "source": [
        "# Split train-validation\n",
        "split_border = int(len(sentiments)*0.8)\n",
        "reviews_train, reviews_validation = reviews[:split_border], reviews[split_border:]\n",
        "sentiments_train, sentiments_validation = sentiments[:split_border], sentiments[split_border:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Sm1dvCddc6"
      },
      "source": [
        "input_ids, attention_mask, sentiments_train = preprocess(reviews_train, sentiments_train)\n",
        "# Combine the training inputs into a TensorDataset\n",
        "train_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    sentiments_train)\n",
        "\n",
        "input_ids, attention_mask, sentiments_validation = preprocess(reviews_validation, sentiments_validation)\n",
        "# Combine the validation inputs into a TensorDataset\n",
        "validation_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    sentiments_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaIdMxlirdFc"
      },
      "source": [
        "# size of 16 or 32.\n",
        "batch_size = 5\n",
        "\n",
        "# Create the DataLoaders\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size)\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            validation_dataset,\n",
        "            sampler = SequentialSampler(validation_dataset),\n",
        "            batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFsR2OSQu_1Q",
        "outputId": "ef293483-2638-40b0-fcb8-0116216ec113"
      },
      "source": [
        "try:\n",
        "    state_dict = torch.load(\"/content/drive/MyDrive/Colab Notebooks/u.pt\")\n",
        "    print(\"Loading trained model...\")\n",
        "    model = CamembertForSequenceClassification.from_pretrained(\n",
        "    'camembert-base',\n",
        "    state_dict=state_dict)\n",
        "    print(\"Trained model loaded!\")\n",
        "except Exception as e:\n",
        "    print(\"Enable to load trained model.\")\n",
        "    print(e)\n",
        "    model = CamembertForSequenceClassification.from_pretrained(\n",
        "        'camembert-base',\n",
        "        num_labels = 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading trained model...\n",
            "Enable to load trained model.\n",
            "Error(s) in loading state_dict for CamembertForSequenceClassification:\n",
            "\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([6, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n",
            "\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7vUl8O2gAUM"
      },
      "source": [
        "def predict(reviews, model=model):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        input_ids, attention_mask = preprocess(reviews)\n",
        "        retour = model(input_ids, attention_mask=attention_mask)\n",
        "        print(retour)\n",
        "        return torch.argmax(retour[0], dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjAyMcRW0bVW"
      },
      "source": [
        "def evaluate(reviews, sentiments, metric='report'):\n",
        "    predictions = predict(reviews)\n",
        "    if metric == 'report':\n",
        "        return metrics.classification_report(sentiments, predictions, zero_division=0)\n",
        "    elif metric == 'matrix':\n",
        "        return metrics.confusion_matrix(sentiments, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEvYTvehrgkY"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0DoJqlPwbZS"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # Learning Rate - Default is 5e-5\n",
        "                  eps = 1e-8 # Adam Epsilon  - Default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELf3ehrNxY3k",
        "outputId": "44033ebc-7105-404a-ed7d-07ffcee4c6c0"
      },
      "source": [
        "# Training loop\n",
        "training_stats = []\n",
        "                                                                                \n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]\n",
        "# (Note that this is not the same as the number of training samples)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# This variable will evaluate the convergence on the training\n",
        "consecutive_epochs_with_no_improve = 0\n",
        "\n",
        "# Training\n",
        "for epoch in range(0, epochs):\n",
        "    \n",
        "    print(\"\")\n",
        "    print(f'########## Epoch {epoch} / {epochs} ##########')\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = time.time() - t0\n",
        "            \n",
        "            # Report progress\n",
        "            print(f'  Batch {step}  of  {len(train_dataloader)}    Elapsed: {format_time(elapsed)}.')\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the 'device' using the 'to' method\n",
        "        #\n",
        "        # 'batch' contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: skills \n",
        "        input_id = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        sentiment = batch[2].to(device)\n",
        "\n",
        "        # Clear any previously calculated gradients before performing a backward pass\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch)\n",
        "        # the loss (because we provided skills) and the \"logits\"--the model\n",
        "        # outputs prior to activation\n",
        "        loss, logits = model(input_id, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=attention_mask, \n",
        "                             labels=sentiment)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. 'loss' is a Tensor containing a\n",
        "        # single value; the '.item()' function just returns the Python value \n",
        "        # from the tensor\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)   \n",
        "\n",
        "    if epoch > 0:\n",
        "        if min([stat['Training Loss'] for stat in training_stats]) <= avg_train_loss:\n",
        "            # i.e. If there is not improvement\n",
        "            consecutive_epochs_with_no_improve += 1\n",
        "        else:\n",
        "            # If there is improvement\n",
        "            consecutive_epochs_with_no_improve = 0\n",
        "            print(\"Model saved!\")\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/u.pt\")\n",
        "    \n",
        "    # Measure how long this epoch took\n",
        "    training_time = time.time() - t0\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "    \n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "    if consecutive_epochs_with_no_improve == 2:\n",
        "        print(\"Stop training : The loss has not changed since 2 epochs!\")\n",
        "        break\n",
        "\n",
        "print(\"Model saved!\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/u.json', 'w+') as outfile:\n",
        "    json.dump(training_stats, outfile)\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/u.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Epoch 0 / 3 ##########\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch 40  of  192    Elapsed: 0:08:17.\n",
            "  Batch 80  of  192    Elapsed: 0:16:29.\n",
            "  Batch 120  of  192    Elapsed: 0:24:42.\n",
            "  Batch 160  of  192    Elapsed: 0:32:54.\n",
            "\n",
            "  Average training loss: 1.63\n",
            "  Training epoch took: 2366.8357627391815\n",
            "\n",
            "########## Epoch 1 / 3 ##########\n",
            "Training...\n",
            "  Batch 40  of  192    Elapsed: 0:08:14.\n",
            "  Batch 80  of  192    Elapsed: 0:16:26.\n",
            "  Batch 120  of  192    Elapsed: 0:24:38.\n",
            "  Batch 160  of  192    Elapsed: 0:32:49.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 1.24\n",
            "  Training epoch took: 2370.80242729187\n",
            "\n",
            "########## Epoch 2 / 3 ##########\n",
            "Training...\n",
            "  Batch 40  of  192    Elapsed: 0:08:53.\n",
            "  Batch 80  of  192    Elapsed: 0:17:46.\n",
            "  Batch 120  of  192    Elapsed: 0:26:36.\n",
            "  Batch 160  of  192    Elapsed: 0:35:25.\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 1.08\n",
            "  Training epoch took: 2552.5376801490784\n",
            "Model saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7YR5jlK52QL"
      },
      "source": [
        "# **Camembert Model Evalutation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbcXrU66sICP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "outputId": "39586d4b-a7c4-4e90-c6b4-41914be9b638"
      },
      "source": [
        "# Evaluation with the confusion matrix\n",
        "import seaborn\n",
        "confusion_matrix = evaluate(reviews, sentiments, 'matrix')\n",
        "report = evaluate(reviews, sentiments, 'report')\n",
        "print(report)\n",
        "seaborn.heatmap(confusion_matrix)\n",
        "# precision    recall  f1-score   support\n",
        "\n",
        "#            0       0.96      0.96      0.96       482\n",
        "#            1       0.98      0.99      0.99      1322\n",
        "\n",
        "#     accuracy                           0.98      1804\n",
        "#    macro avg       0.97      0.97      0.97      1804\n",
        "# weighted avg       0.98      0.98      0.98      1804"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[-1.1125, -1.1510, -0.8915,  0.7394,  1.2202,  1.3181],\n",
            "        [-1.2903, -1.1338, -0.6934,  1.0808,  1.2094,  0.9765],\n",
            "        [ 0.0743,  1.2150,  1.2356, -0.4675, -0.9165, -1.0682],\n",
            "        ...,\n",
            "        [ 1.3911,  1.2292,  0.6021, -0.9557, -1.1522, -1.1850],\n",
            "        [-1.2455, -1.1513, -0.7815,  1.0010,  1.2371,  1.0839],\n",
            "        [ 1.8566,  0.6280,  0.0489, -0.8318, -0.8864, -0.9158]]),)\n",
            "(tensor([[-1.1125, -1.1510, -0.8915,  0.7394,  1.2202,  1.3181],\n",
            "        [-1.2903, -1.1338, -0.6934,  1.0808,  1.2094,  0.9765],\n",
            "        [ 0.0743,  1.2150,  1.2356, -0.4675, -0.9165, -1.0682],\n",
            "        ...,\n",
            "        [ 1.3911,  1.2292,  0.6021, -0.9557, -1.1522, -1.1850],\n",
            "        [-1.2455, -1.1513, -0.7815,  1.0010,  1.2371,  1.0839],\n",
            "        [ 1.8566,  0.6280,  0.0489, -0.8318, -0.8864, -0.9158]]),)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.83      0.67        35\n",
            "           1       0.61      0.47      0.54        40\n",
            "           2       0.78      0.73      0.75        52\n",
            "           3       0.53      0.49      0.51        35\n",
            "           4       0.43      0.51      0.47        35\n",
            "           5       0.71      0.56      0.62        43\n",
            "\n",
            "    accuracy                           0.60       240\n",
            "   macro avg       0.60      0.60      0.59       240\n",
            "weighted avg       0.62      0.60      0.60       240\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1eed7f3d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}