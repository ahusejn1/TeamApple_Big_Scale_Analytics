{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cam_Batchsize16_Epoch5_accuracy48.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JPIU-Jh5iwI"
      },
      "source": [
        "# **Package importation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK910WqOauTw",
        "outputId": "f83533e0-4301-4178-878d-7a08b0791a76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNS0ecn-cLBJ",
        "outputId": "db6dd097-ad38-44a5-c298-84df28e91458"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.95)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.17.83)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.5.2)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.83 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.20.83)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.83->boto3->transformers==2.8.0) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKTsS8qmHKM0"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split, \\\n",
        "                            DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import CamembertForSequenceClassification, CamembertTokenizer, \\\n",
        "                         AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Functions : preprocess() (create dataloaders from raw data) \n",
        "# load_models() (load tokenizers and models) training() (loop of one training step) evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkq_Dw-b5wLS"
      },
      "source": [
        "# **Data uploading and preparing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "p-aiyGlVhJbN",
        "outputId": "88d7488c-38d8-42a2-f6e9-a11885c00a94"
      },
      "source": [
        "#upload the preprocessed dataset\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/dataset/22fdbaea-415d-4685-8132-1916959ca359_train.csv\")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C'est pour quand ?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je pense que c'est bon.</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C'est pas mal.</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Qu'est-ce que vous faites ?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C'est bien !</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      sentence difficulty\n",
              "0           C'est pour quand ?         A1\n",
              "1      Je pense que c'est bon.         A1\n",
              "2               C'est pas mal.         A1\n",
              "3  Qu'est-ce que vous faites ?         A1\n",
              "4                 C'est bien !         A1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "HBmdIfppbdY1",
        "outputId": "b6e81205-79c0-43ac-e175-26a7d2346b79"
      },
      "source": [
        "#normalizing the difficulty data from letter to number for the camembert model\n",
        "dataset = dataset.replace(['A1', 'A2', 'B1', 'B2', 'C1', 'C2'], [0,1,2,3,4,5])\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C'est pour quand ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je pense que c'est bon.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C'est pas mal.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Qu'est-ce que vous faites ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C'est bien !</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>Le problème va du garçon de café tentant inint...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Les lois de programmation mentionnées à l'anté...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>La conscience malheureuse, c'est donc le mauva...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Comme Monsieur, un informaticien fondateur de ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Un passager peut se tenir à califourchon derri...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  difficulty\n",
              "0                                    C'est pour quand ?           0\n",
              "1                               Je pense que c'est bon.           0\n",
              "2                                        C'est pas mal.           0\n",
              "3                           Qu'est-ce que vous faites ?           0\n",
              "4                                          C'est bien !           0\n",
              "...                                                 ...         ...\n",
              "4795  Le problème va du garçon de café tentant inint...           5\n",
              "4796  Les lois de programmation mentionnées à l'anté...           5\n",
              "4797  La conscience malheureuse, c'est donc le mauva...           5\n",
              "4798  Comme Monsieur, un informaticien fondateur de ...           5\n",
              "4799  Un passager peut se tenir à califourchon derri...           5\n",
              "\n",
              "[4800 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSlIQVsgb_H-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "52f508e9-938f-4a05-a4b9-87efcecd4dd5"
      },
      "source": [
        "#rename the columns \n",
        "dataset.columns = ['review','sentiment']\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C'est pour quand ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je pense que c'est bon.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C'est pas mal.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Qu'est-ce que vous faites ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C'est bien !</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>Le problème va du garçon de café tentant inint...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Les lois de programmation mentionnées à l'anté...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>La conscience malheureuse, c'est donc le mauva...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Comme Monsieur, un informaticien fondateur de ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Un passager peut se tenir à califourchon derri...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 review  sentiment\n",
              "0                                    C'est pour quand ?          0\n",
              "1                               Je pense que c'est bon.          0\n",
              "2                                        C'est pas mal.          0\n",
              "3                           Qu'est-ce que vous faites ?          0\n",
              "4                                          C'est bien !          0\n",
              "...                                                 ...        ...\n",
              "4795  Le problème va du garçon de café tentant inint...          5\n",
              "4796  Les lois de programmation mentionnées à l'anté...          5\n",
              "4797  La conscience malheureuse, c'est donc le mauva...          5\n",
              "4798  Comme Monsieur, un informaticien fondateur de ...          5\n",
              "4799  Un passager peut se tenir à califourchon derri...          5\n",
              "\n",
              "[4800 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Set5ai-x4_gV"
      },
      "source": [
        "#The 5 code below are aimed to delete proportionally 75% of rows for having enough colab ram to run completely the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnIjECR0lpOB"
      },
      "source": [
        "dataset = dataset.drop(range(4199,4799))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5aw1zXLlpC7"
      },
      "source": [
        "dataset = dataset.drop(range(3399,3999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS18JsXxlo4g"
      },
      "source": [
        "dataset = dataset.drop(range(2599,3199))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICeE7Ihglouj"
      },
      "source": [
        "dataset = dataset.drop(range(1799,2399))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ieA7EZxlok9"
      },
      "source": [
        "dataset = dataset.drop(range(999,1599))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov4m9cg9loYc"
      },
      "source": [
        "dataset = dataset.drop(range(199,799))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "iyB8tJcBEvdH",
        "outputId": "d03419a1-7b4e-4e58-f8dd-d4cc3683d191"
      },
      "source": [
        "#shuffling all the columns because we notice that our camembert model processed differently if there is no order in the dataset\n",
        "dataset = shuffle(dataset)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>Qu'est-ce que vous voulez ?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3241</th>\n",
              "      <td>La politique vaccinale s'accompagne aussi de n...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4019</th>\n",
              "      <td>Victoire en 1906: la loi du 13 juillet instaur...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4007</th>\n",
              "      <td>Gutrie (Petty, 2000) citent les initiatives ma...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2402</th>\n",
              "      <td>Finies les façades grises et ternes, terminée ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2409</th>\n",
              "      <td>Dénoncer une discrimination collectivement acc...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406</th>\n",
              "      <td>Ce récit fascine toujours notre science-fictio...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>Bonne idée.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1647</th>\n",
              "      <td>Je suis fatiguée et préfère prendre le métro p...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3218</th>\n",
              "      <td>Les avantages et inconvénients offerts par les...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 review  sentiment\n",
              "801                         Qu'est-ce que vous voulez ?          1\n",
              "3241  La politique vaccinale s'accompagne aussi de n...          4\n",
              "4019  Victoire en 1906: la loi du 13 juillet instaur...          5\n",
              "4007  Gutrie (Petty, 2000) citent les initiatives ma...          5\n",
              "2402  Finies les façades grises et ternes, terminée ...          3\n",
              "...                                                 ...        ...\n",
              "2409  Dénoncer une discrimination collectivement acc...          3\n",
              "2406  Ce récit fascine toujours notre science-fictio...          3\n",
              "799                                         Bonne idée.          0\n",
              "1647  Je suis fatiguée et préfère prendre le métro p...          2\n",
              "3218  Les avantages et inconvénients offerts par les...          4\n",
              "\n",
              "[300 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQxYbDgi5V_W"
      },
      "source": [
        "## **Camembert Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shklKqs4cCyT"
      },
      "source": [
        "reviews = dataset['review'].values.tolist()\n",
        "sentiments = dataset['sentiment'].values.tolist()\n",
        "\n",
        "TOKENIZER = CamembertTokenizer.from_pretrained(\n",
        "    'camembert-base',\n",
        "    do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfs9Ot9N4jdz"
      },
      "source": [
        "def preprocess(raw_reviews, sentiments=None):\n",
        "    \"\"\"\n",
        "    Cette fonction prends de la donnée brute en argument et retourne un 'dataloader' pytorch\n",
        "\n",
        "    Args\n",
        "        raw_reviews (array-like) : Une liste de reviews sous forme de 'str'\n",
        "        \n",
        "        sentiments : Une liste 'sentiments' (0 = negatif, 1 = positif) de la meme taille que\n",
        "                     'raw_review'\n",
        "    \n",
        "    Returns\n",
        "        inputs_ids, attention_masks, sentiments(optionel) : Objet  de PyTorch qui contient \n",
        "                    les versions tokenisees et encodees des donnees brutes\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    encoded_batch = TOKENIZER.batch_encode_plus(raw_reviews,\n",
        "                                                add_special_tokens=False,\n",
        "                                                pad_to_max_length=True,\n",
        "                                                return_attention_mask=True,\n",
        "                                                return_tensors = 'pt')\n",
        "    if sentiments:\n",
        "        sentiments = torch.tensor(sentiments)\n",
        "        return encoded_batch['input_ids'], encoded_batch['attention_mask'], sentiments\n",
        "    return encoded_batch['input_ids'], encoded_batch['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-6WezGJpJu-"
      },
      "source": [
        "# Split train-validation\n",
        "split_border = int(len(sentiments)*0.8)\n",
        "reviews_train, reviews_validation = reviews[:split_border], reviews[split_border:]\n",
        "sentiments_train, sentiments_validation = sentiments[:split_border], sentiments[split_border:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Sm1dvCddc6"
      },
      "source": [
        "input_ids, attention_mask, sentiments_train = preprocess(reviews_train, sentiments_train)\n",
        "# Combine the training inputs into a TensorDataset\n",
        "train_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    sentiments_train)\n",
        "\n",
        "input_ids, attention_mask, sentiments_validation = preprocess(reviews_validation, sentiments_validation)\n",
        "# Combine the validation inputs into a TensorDataset\n",
        "validation_dataset = TensorDataset(\n",
        "    input_ids,\n",
        "    attention_mask,\n",
        "    sentiments_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaIdMxlirdFc"
      },
      "source": [
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size)\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            validation_dataset,\n",
        "            sampler = SequentialSampler(validation_dataset),\n",
        "            batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFsR2OSQu_1Q",
        "outputId": "2a45c9c8-998b-4847-cdd6-f2b461f75e70"
      },
      "source": [
        "try:\n",
        "    state_dict = torch.load(\"/content/drive/MyDrive/dataset/u.pt\")\n",
        "    print(\"Loading trained model...\")\n",
        "    model = CamembertForSequenceClassification.from_pretrained(\n",
        "    'camembert-base',\n",
        "    state_dict=state_dict)\n",
        "    print(\"Trained model loaded!\")\n",
        "except Exception as e:\n",
        "    print(\"Enable to load trained model.\")\n",
        "    print(e)\n",
        "    model = CamembertForSequenceClassification.from_pretrained(\n",
        "        'camembert-base',\n",
        "        num_labels = 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading trained model...\n",
            "Enable to load trained model.\n",
            "Error(s) in loading state_dict for CamembertForSequenceClassification:\n",
            "\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([6, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n",
            "\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7vUl8O2gAUM"
      },
      "source": [
        "def predict(reviews, model=model):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        input_ids, attention_mask = preprocess(reviews)\n",
        "        retour = model(input_ids, attention_mask=attention_mask)\n",
        "        print(retour)\n",
        "        return torch.argmax(retour[0], dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjAyMcRW0bVW"
      },
      "source": [
        "def evaluate(reviews, sentiments, metric='report'):\n",
        "    predictions = predict(reviews)\n",
        "    if metric == 'report':\n",
        "        return metrics.classification_report(sentiments, predictions, zero_division=0)\n",
        "    elif metric == 'matrix':\n",
        "        return metrics.confusion_matrix(sentiments, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEvYTvehrgkY"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0DoJqlPwbZS"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # Learning Rate - Default is 5e-5\n",
        "                  eps = 1e-8 # Adam Epsilon  - Default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELf3ehrNxY3k",
        "outputId": "f50e1352-56fa-4602-d661-b1b3c27d5ffb"
      },
      "source": [
        "# Training loop\n",
        "training_stats = []\n",
        "                                                                                \n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]\n",
        "# (Note that this is not the same as the number of training samples)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# This variable will evaluate the convergence on the training\n",
        "consecutive_epochs_with_no_improve = 0\n",
        "\n",
        "# Training\n",
        "for epoch in range(0, epochs):\n",
        "    \n",
        "    print(\"\")\n",
        "    print(f'########## Epoch {epoch} / {epochs} ##########')\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = time.time() - t0\n",
        "            \n",
        "            # Report progress\n",
        "            print(f'  Batch {step}  of  {len(train_dataloader)}    Elapsed: {format_time(elapsed)}.')\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the 'device' using the 'to' method\n",
        "        #\n",
        "        # 'batch' contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: skills \n",
        "        input_id = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        sentiment = batch[2].to(device)\n",
        "\n",
        "        # Clear any previously calculated gradients before performing a backward pass\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch)\n",
        "        # the loss (because we provided skills) and the \"logits\"--the model\n",
        "        # outputs prior to activation\n",
        "        loss, logits = model(input_id, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=attention_mask, \n",
        "                             labels=sentiment)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. 'loss' is a Tensor containing a\n",
        "        # single value; the '.item()' function just returns the Python value \n",
        "        # from the tensor\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)   \n",
        "\n",
        "    if epoch > 0:\n",
        "        if min([stat['Training Loss'] for stat in training_stats]) <= avg_train_loss:\n",
        "            # i.e. If there is not improvement\n",
        "            consecutive_epochs_with_no_improve += 1\n",
        "        else:\n",
        "            # If there is improvement\n",
        "            consecutive_epochs_with_no_improve = 0\n",
        "            print(\"Model saved!\")\n",
        "            torch.save(model.state_dict(), \"/content/drive/MyDrive/dataset/u.pt\")\n",
        "    \n",
        "    # Measure how long this epoch took\n",
        "    training_time = time.time() - t0\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "    \n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "    if consecutive_epochs_with_no_improve == 2:\n",
        "        print(\"Stop training : The loss has not changed since 2 epochs!\")\n",
        "        break\n",
        "\n",
        "print(\"Model saved!\")\n",
        "with open('/content/drive/MyDrive/dataset/u.json', 'w+') as outfile:\n",
        "    json.dump(training_stats, outfile)\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/dataset/u.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "########## Epoch 0 / 5 ##########\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.79\n",
            "  Training epoch took: 661.6952102184296\n",
            "\n",
            "########## Epoch 1 / 5 ##########\n",
            "Training...\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 1.76\n",
            "  Training epoch took: 646.0364723205566\n",
            "\n",
            "########## Epoch 2 / 5 ##########\n",
            "Training...\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 1.73\n",
            "  Training epoch took: 636.836353302002\n",
            "\n",
            "########## Epoch 3 / 5 ##########\n",
            "Training...\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 1.71\n",
            "  Training epoch took: 626.7186727523804\n",
            "\n",
            "########## Epoch 4 / 5 ##########\n",
            "Training...\n",
            "Model saved!\n",
            "\n",
            "  Average training loss: 1.69\n",
            "  Training epoch took: 627.2071509361267\n",
            "Model saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoAmAVv76HdY"
      },
      "source": [
        "# **Camembert Model Evalutation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICQDZKcSgUi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "outputId": "715fe257-4c27-43be-af98-517a1977788d"
      },
      "source": [
        "import seaborn\n",
        "confusion_matrix = evaluate(reviews, sentiments, 'matrix')\n",
        "report = evaluate(reviews, sentiments, 'report')\n",
        "print(report)\n",
        "seaborn.heatmap(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 0.2687,  0.1936,  0.0386,  0.0519, -0.0969, -0.2640],\n",
            "        [-0.0929, -0.0823,  0.1126,  0.1889,  0.1410,  0.0114],\n",
            "        [-0.0906, -0.1397,  0.0891,  0.2253,  0.0499,  0.0260],\n",
            "        ...,\n",
            "        [ 0.2631,  0.1168, -0.0579,  0.0376, -0.0729, -0.2507],\n",
            "        [ 0.0768, -0.0053,  0.1580,  0.0737, -0.0714, -0.1569],\n",
            "        [-0.1625, -0.1732,  0.0384,  0.2116,  0.0700,  0.0541]]),)\n",
            "(tensor([[ 0.2687,  0.1936,  0.0386,  0.0519, -0.0969, -0.2640],\n",
            "        [-0.0929, -0.0823,  0.1126,  0.1889,  0.1410,  0.0114],\n",
            "        [-0.0906, -0.1397,  0.0891,  0.2253,  0.0499,  0.0260],\n",
            "        ...,\n",
            "        [ 0.2631,  0.1168, -0.0579,  0.0376, -0.0729, -0.2507],\n",
            "        [ 0.0768, -0.0053,  0.1580,  0.0737, -0.0714, -0.1569],\n",
            "        [-0.1625, -0.1732,  0.0384,  0.2116,  0.0700,  0.0541]]),)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.98      0.66        50\n",
            "           1       1.00      0.08      0.15        50\n",
            "           2       0.75      0.82      0.78        50\n",
            "           3       0.33      0.92      0.49        50\n",
            "           4       1.00      0.10      0.18        50\n",
            "           5       0.00      0.00      0.00        50\n",
            "\n",
            "    accuracy                           0.48       300\n",
            "   macro avg       0.60      0.48      0.38       300\n",
            "weighted avg       0.60      0.48      0.38       300\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2252bef410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}